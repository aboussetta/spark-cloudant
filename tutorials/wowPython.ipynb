{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Introduction\n",
    "\n",
    "In this tutorial, we will use Spark Streaming to stream data from a Cloudant database, and process this continously received stream of data using Spark SQL. \n",
    "\n",
    "Our processing pipeline goes through three stages:\n",
    "1. *_changes feed* is streamed from the given Cloudant database using `CloudantReceiver`. `CloudantReceiver` will receive _changes feed of the database, extract individual JSON documents from the feed, and store these documents in Spark's memory for processing by Spark Streaming. \n",
    "2. Spark Streaming will break up this continous stream of documents into batches. Each batch is a separate RDD, and in our case represents a set of documents collected within 10 secs window. This sequence of batches, or sequence of RDDs is what is called a discretized stream or DStream. \n",
    "3. Each RDD of the DStream is processed using Spark SQL.\n",
    "\n",
    "```\n",
    "|                1                  | -> |            2               |    |          3             |\n",
    "|_changes feed ->... doc3 doc2 doc1 | -> |... [doc4 doc3] [doc2 doc1] | -> |... [pBatch2] [pBatch1] |\n",
    "|      CloudantReceiver             | -> | Spark Streaming: DStream   | -> |      Spark SQL         |\n",
    "```\n",
    "\n",
    "In the steps below, we:\n",
    "1. Initialize StreamingContext and DStream\n",
    "2. Define processing of DStream using Spark SQL\n",
    "3. Actually start processing, and stop it after some time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. Initializing DStream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Provide the details of your cloudant account in *properties* map:\n",
    "\n",
    "- *cloudant.host* - the fully qualified account https URL\n",
    "- *cloudant.username* - the Cloudant account username\n",
    "- *cloudant.password* - the Cloudant account password\n",
    "- *database* - database which changes you want to recieve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.streaming.{ Seconds, StreamingContext, Time }\n",
    "import org.apache.spark.{ SparkContext, SparkConf}\n",
    "import org.apache.spark.sql.SQLContext\n",
    "import org.apache.spark.rdd.RDD\n",
    "import java.util.concurrent.atomic.AtomicLong\n",
    "\n",
    "import com.cloudant.spark.CloudantReceiver\n",
    "\n",
    "\n",
    "val properties = Map(\n",
    "    \"cloudant.host\"-> \"wow1.cloudant.com\", \n",
    "    \"cloudant.username\"-> \"wow1\",\n",
    "    \"cloudant.password\"-> \"wow1Cloudant\",\n",
    "    \"database\"-> \"election2016\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Initialize StreamingContext and DStream\n",
    "\n",
    "- Initialize a StreamingContext with a 10 seconds batch size\n",
    "- Create a DStream of database changes using CloudantReceiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val ssc = new StreamingContext(sc, Seconds(10))\n",
    "val changesDStream = ssc.receiverStream(new CloudantReceiver(properties))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define processing of DStreams\n",
    "\n",
    "- Get SQLContext\n",
    "- For every batch:\n",
    "  - Create a dataframe `tweetsDF`\n",
    "  - Create `tweetsDF2` dataframe with fields `gender`, `state`, and `polarity` \n",
    "  - Calculate and display the cumulative count of tweets\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val sqlContext = new SQLContext(sc)\n",
    "import sqlContext.implicits._\n",
    "\n",
    "val curTotalCount = new AtomicLong(0)\n",
    "changesDStream.foreachRDD((rdd: RDD[String], time: Time) => {\n",
    "    println(s\"========= $time =========\")\n",
    "    val tweetsDF = sqlContext.read.json(rdd)\n",
    "    \n",
    "    if (!tweetsDF.schema.isEmpty) {\n",
    "        val tweetsDF2 = tweetsDF.select($\"cde.author.gender\", \n",
    "                $\"cde.author.location.state\",\n",
    "                $\"cde.content.sentiment.polarity\")\n",
    "        tweetsDF2.show(10)\n",
    "        \n",
    "        curTotalCount.getAndAdd(tweetsDF2.count())\n",
    "        println(\"Current total count:\" + curTotalCount)\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Start receiving and processing of data\n",
    "\n",
    "- Start StreamingContext\n",
    "- Allow processing to run for 120 secs\n",
    "- Manually stop processing \n",
    "\n",
    "All previous instructions were just initilizations and definions, and nothing will happen until we start StreamingContext. After the start, the data will be received and processed. Since, DStream is continous,  it will not stop until we manually stop the processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= 1473435100000 ms =========\n",
      "+-------+--------+--------+\n",
      "| gender|   state|polarity|\n",
      "+-------+--------+--------+\n",
      "|   male|    Utah| NEUTRAL|\n",
      "|unknown|    null| NEUTRAL|\n",
      "|   male|        | NEUTRAL|\n",
      "|   null| Arizona|    null|\n",
      "|   male|New York|POSITIVE|\n",
      "|unknown|    null| NEUTRAL|\n",
      "|unknown|    Utah| NEUTRAL|\n",
      "|unknown|        |POSITIVE|\n",
      "|   null|    null|    null|\n",
      "|unknown|        | NEUTRAL|\n",
      "+-------+--------+--------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Current total count:300\n",
      "========= 1473435110000 ms =========\n",
      "========= 1473435120000 ms =========\n",
      "========= 1473435130000 ms =========\n",
      "========= 1473435140000 ms =========\n",
      "========= 1473435150000 ms =========\n",
      "========= 1473435160000 ms =========\n",
      "========= 1473435170000 ms =========\n",
      "========= 1473435180000 ms =========\n",
      "+-------+--------+--------+\n",
      "| gender|   state|polarity|\n",
      "+-------+--------+--------+\n",
      "|   male|        | NEUTRAL|\n",
      "|unknown|    Utah| NEUTRAL|\n",
      "|unknown|    null| NEUTRAL|\n",
      "|unknown|    null| NEUTRAL|\n",
      "|   male|    Utah| NEUTRAL|\n",
      "|   male|New York|POSITIVE|\n",
      "|   null| Arizona|    null|\n",
      "|unknown|        | NEUTRAL|\n",
      "|   null|    null|    null|\n",
      "|unknown|        |POSITIVE|\n",
      "+-------+--------+--------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Current total count:600\n",
      "========= 1473435190000 ms =========\n",
      "========= 1473435200000 ms =========\n",
      "========= 1473435210000 ms =========\n",
      "+-------+--------------------+--------+\n",
      "| gender|               state|polarity|\n",
      "+-------+--------------------+--------+\n",
      "|unknown|                Utah| NEUTRAL|\n",
      "|   null|             Arizona|    null|\n",
      "|unknown|                null| NEUTRAL|\n",
      "|unknown|            Maryland|NEGATIVE|\n",
      "|unknown|                    | NEUTRAL|\n",
      "|   male|        Pennsylvania| NEUTRAL|\n",
      "|   null|                null|    null|\n",
      "|unknown|            Virginia| NEUTRAL|\n",
      "|   male|District of Columbia|NEGATIVE|\n",
      "|unknown|       Massachusetts| NEUTRAL|\n",
      "+-------+--------------------+--------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Current total count:700\n"
     ]
    }
   ],
   "source": [
    "ssc.start()\n",
    "Thread.sleep(120000L)\n",
    "ssc.stop(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.10",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}